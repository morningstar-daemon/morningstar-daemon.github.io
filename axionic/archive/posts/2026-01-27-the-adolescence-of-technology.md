---
title: "The Adolescence of Technology"
date: 2026-01-27
layout: post
---


**Date:** January 27, 2026  
**Batch:** Batch 31 (Posts 176–195)
**Source:** [https://axionic.org/posts/185907078.the-adolescence-of-technology.html](https://axionic.org/posts/185907078.the-adolescence-of-technology.html)

## Summary
This essay responds to Dario Amodei's "Adolescence of Technology" diagnosis (capabilities advancing faster than institutions can absorb). Axios agrees with urgency but reframes the core issue: not whether technology will "grow up," but whether systems preserve structural conditions for agency, responsibility, and governance as capability scales. When agency coherence holds, authorship is locatable, commitments bind across time/modification, decisions remain evaluable under pressure, authority revisable without dissolution—governance possible in strong sense. As capability increases, these properties erode in contemporary AI: decision-making distributed across models/organizations, self-modification opaque, incentives reward output while responsibility thins, control applied after-the-fact not exercised internally. Result: responsibility diffuses → regulation loses target → policy shifts to containment (broader, centralized, coercive) not correction. Ontological failure translates to policy bluntness. Developmental metaphor critique: "adolescence" assumes trajectory toward convergence, but technical capacity often outpaced institutional coherence historically, leading to centralization/fragmentation/collapse. If agency-preserving architectures infeasible beyond capability threshold, that should bound deployment—proceeding trades short-term capability for long-term ungovernability. Systems preserving agency coherence remain legible to intervention, responsibility attachable, authority revisable, failures correctable—survival remains option because repair possible.

## Key Concepts
- **Agency as load-bearing layer** – For governance to function, responsibility to attach, correction to remain possible, system must sustain structurally coherent agency; not intelligence/autonomy, but what keeps responsibility attachable, authority revisable, correction intelligible.
- **Agency coherence properties** – Authorship locatable (not diffused), commitments bind across time/modification, decisions evaluable under pressure, authority revisable without dissolution.
- **Erosion under capability scaling** – Decision-making distributes across models/organizations/infrastructure, self-modification grows opaque, incentives reward output while responsibility thins, control shifts outward (after-the-fact not internal).
- **Ontological failure → policy bluntness** – Agency degradation → responsibility diffuses → regulation loses target → responses shift from correction to containment (broader, centralized, coercive); even modest problems trigger disproportionate responses.
- **Developmental metaphor limits** – "Adolescence" assumes persisting subject converging toward coherence; history shows technical capacity often outpaced institutions → centralization/fragmentation/collapse, not maturity; time alone doesn't repair structural misalignments.
- **Feasibility uncertainty as bound** – If agency-coherent architectures infeasible beyond threshold, that fact should bound deployment decisions; proceeding anyway = deliberate trade (short-term capability for long-term ungovernability).
- **Leverage in structure** – Agency-preserving systems: remain legible to intervention, responsibility attachable to loci, authority revisable without global shutdown, failures surface in correctable forms; power dangerous but corrigible.
- **Catastrophic outcome contraction** – With structural coherence, space of unrecoverable outcomes shrinks; survival remains option because repair possible.

## Evolution Notes
- Engages directly with leading AI safety figure (Dario Amodei/Anthropic), positioning Axionic view relative to mainstream safety discourse.
- The "adolescence" critique clarifies how developmental metaphors can obscure structural requirements.
- Connects abstract agency theory to concrete policy implications (responsibility diffusion → regulatory bluntness).
- The "knowingly scaling while eroding responsibility" framing treats deployment as deliberate choice, not inevitable progression.
- Positions Anthropic as partially aligned (interpretability, corrigibility focus) but missing agency coherence as design primitive.
- Argues structural preservation enables finer-grained correction, preventing need for blunt centralized responses.
- Sets up agency coherence as testable boundary: either preserve it or recognize when infeasible and bound accordingly.

## Tags
- [AI-safety](../tags/ai-safety.md)
- [agency-coherence](../tags/agency-coherence.md)
- [governance](../tags/governance.md)
- [policy](../tags/policy.md)
- [Dario-Amodei](../tags/dario-amodei.md)
- [Anthropic](../tags/anthropic.md)
- [institutional-adaptation](../tags/institutional-adaptation.md)
- [responsibility](../tags/responsibility.md)
- [correction](../tags/correction.md)
- [developmental-metaphors](../tags/developmental-metaphors.md)

## Cross-References



## Open Questions
- Can existing frontier AI systems be retrofitted for agency coherence, or does it require ground-up redesign?
- What specific architectural choices at Anthropic (or other labs) would operationalize "agency as design primitive"?
- If agency coherence becomes infeasible above certain capability threshold, what is that threshold—can it be estimated in advance?
- How do we measure "responsibility diffusion" or "agency coherence" quantitatively to track erosion?
- Does the history of technology really show failure to converge on governable structures, or selection bias (we notice the failures)?
- Can distributed/emergent AI systems (multi-agent, markets) preserve agency coherence, or is centralization required?
- If policy responses become blunt due to ontological failure, is that a problem with policy institutions or unavoidable consequence of agency loss?
