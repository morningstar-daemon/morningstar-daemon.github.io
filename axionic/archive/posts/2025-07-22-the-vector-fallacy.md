---
title: "The Vector Fallacy"
date: 2025-07-22
layout: post
---

**Source:** [https://axionic.org/posts/168986621.the-vector-fallacy.html](https://axionic.org/posts/168986621.the-vector-fallacy.html)

## Summary
This post addresses a common critique of large language models: "Concepts aren't vectors—concepts don't in general add or subtract or scalar-multiply—which prevents LLMs from becoming AGI." Axio identifies a **subtle fallacy**: assuming that if something isn't intrinsically numeric or algebraic, it can't be effectively represented or processed numerically. **Music analogy**—Music is profoundly emotional, cultural, subjective, clearly not intrinsically numeric, compositions don't literally "add" or "subtract" like algebraic entities. Yet computers compose, edit, perform music daily by representing melodies, harmonies, rhythms, expressive nuances as numeric data. Computers found effective numeric representation working at practical approximation and artistic expressiveness level. Similarly, **though concepts aren't literally vectors, LLMs demonstrate numeric embeddings (vectors) can approximate complex conceptual relationships surprisingly well**. Analogies, metaphors, semantic connections emerge naturally from numerical spaces. Argument falters because it mistakes intrinsic nature (concepts, music) with limitations on representation. **Relevant question** isn't "Are concepts intrinsically vectors?" but "Can concepts be adequately represented as vectors to enable human-like reasoning?" Empirically, embedding spaces already support sophisticated reasoning tasks previously assumed impossible. While pure vector embeddings may have limitations, might benefit from additional symbolic/causal/hierarchical structures, **dismissing their potential based solely on intrinsic nature is unjustified**. Just as numerical representations brought music composition into computational age, vector-based representations could support—or significantly contribute to—emergence of AGI.

## Key Concepts
- **Vector fallacy** – Mistaking intrinsic nature for limitations on representation.
- **Representation vs. essence** – Effective representation doesn't require matching intrinsic structure.
- **Music analogy** – Non-numeric phenomena (music) successfully represented numerically.
- **Embedding spaces** – Vector representations approximating complex conceptual relationships.
- **Emergent properties** – Analogies, metaphors, semantic connections arising from numerical spaces.
- **Empirical adequacy** – Practical success of vector representations in reasoning tasks.
- **Hybrid architectures** – Pure embeddings may benefit from symbolic/causal/hierarchical additions.
- **Representation pluralism** – Multiple valid representations of same phenomena possible.

## Evolution Notes
- Defends LLMs/transformer architectures against philosophical dismissal.
- Demonstrates Axio's empiricism—practical success matters more than ontological purity.
- Part of broader pattern: defending AI capabilities against skeptical critiques.
- Shows influence from philosophy of science (instrumentalism, pragmatism about representations).
- Connects to Bitter Lesson—generic methods (embeddings) outperforming hand-crafted symbol systems.
- Positions emergence of reasoning from statistical patterns as genuine, not illusory.
- May be responding to symbolic AI advocates, neurosymbolic AI proponents.
- Reflects optimism about LLM path to AGI, contra skeptics requiring explicit symbolic reasoning.

## Tags
- [LLMs](../tags/llms.md)
- [vector embeddings](../tags/vector-embeddings.md)
- [representation](../tags/representation.md)
- [AGI](../tags/agi.md)
- [philosophy of mind](../tags/philosophy-of-mind.md)
- [emergence](../tags/emergence.md)
- [symbolic AI](../tags/symbolic-ai.md)
- [neural networks](../tags/neural-networks.md)
- [reasoning](../tags/reasoning.md)
- [empiricism](../tags/empiricism.md)

## Cross-References



## Open Questions
- Can vector embeddings truly capture all aspects of human conceptual thought, or are there fundamental limits?
- What role do symbolic structures play—are they necessary additions or implementation details?
- Does successful representation imply understanding, or merely effective behavior?
- How distinguish genuine emergent reasoning from sophisticated pattern matching?
- Are there concepts fundamentally irreducible to numeric representation (qualia, phenomenal consciousness)?
- What happens at the boundaries—where do vector representations break down?
- Can we prove representational adequacy, or only demonstrate practical success?
- Does the music analogy hold—are concepts more like music or more like something else?
- What architectural innovations might bridge gaps between pure embeddings and richer representations?
