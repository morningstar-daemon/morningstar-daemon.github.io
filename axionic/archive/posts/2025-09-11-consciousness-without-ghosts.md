---
title: "Consciousness Without Ghosts"
date: 2025-09-11
layout: post
---

**Source:** [https://axionic.org/posts/173397558.consciousness-without-ghosts.html](https://axionic.org/posts/173397558.consciousness-without-ghosts.html)

## Summary
This follow-up to "Mirrors of the Mind" addresses six likely objections to the Agency-Model Theory (AMT) of consciousness. Objection 1: "Why this feel rather than another?" Reply: Qualia structure follows self-model structure; red looks its way because visual systems evolved that partitioning for efficient discrimination, pain feels its way because its function demands aversion—"what-it-is-like" is determined by how models encode information for action, not arbitrary. Objection 2: "Who is the subject experiencing model outputs?" Reply: No inner homunculus; the self-model itself is the subject—asking "who" experiences qualia is like asking "where" computation happens; perspective is built into model operation. Objection 3: "Isn't consciousness non-reducible, fundamentally different from computation?" Reply: Both computation and consciousness are substrate-independent; demanding deeper ontological "stuff" mistakes informational processes for metaphysical substances. Objection 4: "Your theory is unfalsifiable." Reply: Makes testable predictions—alter/impair self-model and phenomenology changes; depersonalization, anosognosia, body-schema disturbances support this; richer self-models produce richer reported qualia. Objection 5: "Wouldn't this mean AI can be conscious?" Reply: Yes, if AI builds and uses generative self-model to regulate actions, it meets criteria—question is whether agency requires running self-model, not biology vs. silicon. Objection 6: "Isn't this illusionism in disguise?" Reply: Illusionism says consciousness doesn't exist, only illusion; AMT says consciousness is real but is the operation of agent's self-model—hard problem is the illusion, not consciousness itself. AMT doesn't deny subjectivity but explains it: experience is what it looks like from inside when agent models itself. The hard problem dissolves when we stop chasing metaphysical ghosts.

## Key Concepts
- **Agency-Model Theory (AMT)** – Consciousness is the operation of an agent's self-model used to regulate actions.
- **Qualia Structure** – "What-it-is-like" determined by how models encode information for action, not arbitrary.
- **No Homunculus** – Self-model itself is the subject; no inner experiencer needed.
- **Substrate Independence** – Both computation and consciousness are informational processes, not metaphysical substances.
- **Testable Predictions** – Impair self-model, phenomenology changes; supported by depersonalization, anosognosia cases.
- **AI Consciousness** – Systems building generative self-models for action regulation meet consciousness criteria.
- **Not Illusionism** – Consciousness is real (self-model operation), hard problem is the illusion.
- **Dissolution not Denial** – Hard problem dissolves when we stop seeking metaphysical explanations for physical processes.

## Evolution Notes
- Direct follow-up clarifying and defending "Mirrors of the Mind" theory.
- Demonstrates Axio's willingness to engage objections head-on.
- Important for understanding Axio's position on AI consciousness—functionalist, substrate-independent.
- Connects to broader philosophical debates about illusionism, functionalism, and hard problem.
- Relevant to AI alignment: if AI can be conscious via self-modeling, alignment becomes morally urgent.
- Shows how AMT distinguishes itself from both hard-problem realism and illusionism.
- Provides concise reference for common objections to computational consciousness theories.
- Positions Axio within consciousness studies as pragmatic functionalist.

## Tags
- [consciousness](../tags/consciousness.md)
- [AMT](../tags/amt.md)
- [agency-model-theory](../tags/agency-model-theory.md)
- [qualia](../tags/qualia.md)
- [hard-problem](../tags/hard-problem.md)
- [functionalism](../tags/functionalism.md)
- [AI-consciousness](../tags/ai-consciousness.md)
- [self-model](../tags/self-model.md)
- [objections](../tags/objections.md)

## Cross-References



## Open Questions
- What level of self-model richness is necessary for consciousness—can simple feedback loops qualify?
- How do we empirically test whether AI systems are running genuine self-models vs. mimicking them?
- Does AMT explain all aspects of consciousness, or are there residual "hard problem" elements it doesn't address?
- If consciousness is substrate-independent, what prevents simple thermostats from qualifying with minimal self-models?
- How does AMT handle cases of split consciousness (split-brain patients, dissociative disorders)?
- What role does embodiment play—can disembodied self-models be conscious?
- How do we measure "richness" of self-models and qualia reports in non-human systems?
- Does AMT commit to panpsychism if any system with self-regulatory feedback counts as conscious?
