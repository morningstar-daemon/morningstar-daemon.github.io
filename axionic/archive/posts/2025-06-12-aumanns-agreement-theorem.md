---
title: "Aumann's Agreement Theorem"
date: 2025-06-12
layout: post
---

# Aumann's Agreement Theorem

**Date:** June 12, 2025  
**Batch:** Batch 05 (Posts 101–125)

## Summary
This post explicates Aumann's Agreement Theorem (1976): two perfectly rational Bayesian agents with common knowledge of each other's beliefs and priors cannot agree to disagree—rational updating on shared information must lead to credence convergence. The theorem hinges on perfect Bayesian rationality and common knowledge (infinite mutual knowledge regress). Persistent disagreement implies: different priors, asymmetrical information, or misunderstood reasoning. In practice, these conditions rarely hold—humans have divergent priors, imperfect information, and cognitive biases. Axio applies this to philosophical/theological disagreements (e.g., Trinity): rational agents may assign vastly different credences (1-2% vs. 0.01-0.1%) while both being rational given their priors and epistemic standards. The key insight: rational disagreement is a *diagnostic tool* signaling underlying informational asymmetries or prior differences worth investigating explicitly.

## Key Concepts
- **Aumann's Agreement Theorem** – Rational Bayesian agents with common knowledge cannot agree to disagree; must converge on same credence.
- **Perfect Bayesian rationality** – Strict adherence to Bayes' theorem for belief updating.
- **Common knowledge** – Infinite mutual knowledge: A knows B knows A knows... ad infinitum.
- **Persistent disagreement causes** – Different priors, asymmetric information, misunderstood reasoning processes.
- **Practical limitations** – Real agents lack identical priors, perfect information, and perfect rationality (cognitive biases).
- **Rational disagreement as diagnostic** – Divergence signals hidden assumptions or information asymmetries worth exploring.

## Evolution Notes
- Deepens Bayesian epistemology toolkit from earlier credence/probability work.
- Provides framework for understanding philosophical disagreements (not dismissing them as irrational).
- Connects to agent-relative epistemology: different priors are legitimate, not errors.
- Later work will apply this to political disagreements, value pluralism, and coordination under uncertainty.
- Establishes norm: investigate *why* disagreements persist rather than just tolerating them.

## Tags
- [aumann's agreement theorem](../tags/aumann's-agreement-theorem.md)
- [bayesian epistemology](../tags/bayesian-epistemology.md)
- [rational disagreement](../tags/rational-disagreement.md)
- [common knowledge](../tags/common-knowledge.md)
- [credence](../tags/credence.md)
- [priors](../tags/priors.md)
- [information asymmetry](../tags/information-asymmetry.md)

## Cross-References



## Open Questions
- Can we quantify "closeness to common knowledge" in real-world debates to predict convergence likelihood?
- How should agents with very different priors coordinate action despite rational credence divergence?
- Are there meta-level agreements (about rationality, evidence standards) that enable productive disagreement?
- When should persistent disagreement trigger doubt about one's own rationality vs. confidence in different priors?
